# FACTORY.AI AGI Companion - Environment Configuration

# ======================================================
# REQUIRED API KEYS
# ======================================================

# OpenAI API Configuration (Required)
# Your OpenAI API key is essential for core reasoning and conversation capabilities
# Get one at: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# ======================================================
# OPTIONAL API KEYS & SERVICES
# ======================================================

# Hugging Face Configuration (Optional)
# Enables local model processing, embeddings, and enhanced NLP capabilities
# Get a token at: https://huggingface.co/settings/tokens
HUGGING_FACE_TOKEN=your_hugging_face_token_here

# ======================================================
# VECTOR DATABASE CONFIGURATION
# ======================================================

# Milvus Configuration (Self-hosted vector database)
# Required if using Milvus for knowledge base vector storage
# Default port is 19530 for self-hosted Milvus instances
MILVUS_URL=http://localhost:19530
MILVUS_USERNAME=
MILVUS_PASSWORD=

# Pinecone Configuration (Cloud vector database alternative)
# Required if using Pinecone instead of Milvus
# Get credentials at: https://app.pinecone.io/
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=your_pinecone_environment
PINECONE_INDEX_NAME=agi-companion

# ======================================================
# DATABASE CONFIGURATION
# ======================================================

# SQLite database path (defaults to app data directory if not specified)
# Stores conversations, memory, tasks, and other persistent data
DATABASE_PATH=./data/agi-companion.db

# ======================================================
# KNOWLEDGE BASE CONFIGURATION
# ======================================================

# Path where knowledge base documents will be stored and indexed
KNOWLEDGE_BASE_PATH=./data/knowledge

# Maximum size of knowledge base in GB (affects memory usage)
MAX_KNOWLEDGE_SIZE_GB=300

# Number of documents to process in each indexing batch
# Lower values use less memory but are slower
INDEX_BATCH_SIZE=100

# ======================================================
# AI MODEL CONFIGURATION
# ======================================================

# Default OpenAI model to use for conversations
# Options: gpt-4, gpt-3.5-turbo, etc.
DEFAULT_MODEL=gpt-4

# Model to use for generating embeddings
# Ada embeddings are cost-effective and work well for most use cases
EMBEDDING_MODEL=text-embedding-ada-002

# Maximum tokens to generate in responses
# Higher values allow longer responses but cost more
MAX_TOKENS=4096

# Temperature controls randomness in responses
# 0.0 = deterministic, 1.0 = creative
TEMPERATURE=0.7

# ======================================================
# FEATURE FLAGS
# ======================================================

# Enable/disable proactive AI suggestions based on user behavior
ENABLE_PROACTIVE_SUGGESTIONS=true

# Enable/disable meeting preparation and summarization features
ENABLE_MEETING_INTELLIGENCE=true

# Enable/disable task management capabilities
ENABLE_TASK_MANAGEMENT=true

# Enable/disable project tracking and management
ENABLE_PROJECT_TRACKING=true

# ======================================================
# DEVELOPMENT SETTINGS
# ======================================================

# Enable verbose debugging output
DEBUG_MODE=false

# Logging level: error, warn, info, debug, trace
LOG_LEVEL=info

# ======================================================
# ADVANCED SETTINGS
# ======================================================

# Memory retention period in days (how long to keep memories active)
MEMORY_RETENTION_DAYS=365

# Automatic knowledge base indexing interval in minutes
# Set to 0 to disable automatic indexing
AUTO_INDEX_INTERVAL=60

# Maximum concurrent document processing tasks
MAX_CONCURRENT_PROCESSING=4

# Enable experimental features (may be unstable)
ENABLE_EXPERIMENTAL=false
